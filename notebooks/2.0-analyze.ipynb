{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fxr/.local/share/virtualenvs/pdf_2_ner-Tur0vV_l/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pdftotext\n",
    "import re\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from collections import OrderedDict \n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF file\n",
    "def extract_text(path):\n",
    "    \n",
    "    # Read PDF file\n",
    "    with open(path, \"rb\") as f:\n",
    "        # Load PDF file\n",
    "        pdf = pdftotext.PDF(f)\n",
    "        pdf_text = \"\"\n",
    "        # Iterate over all the pages\n",
    "        for page in pdf:\n",
    "            # Concatenate strings from pages\n",
    "            pdf_text += page\n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all files in the directory with 'pdf' extension\n",
    "pdfs = glob('../assets/pdfs/*.pdf')\n",
    "\n",
    "texts = []\n",
    "for pdf in pdfs:\n",
    "\n",
    "    # Apply function to extract text from PDF files\n",
    "    pdf_text = extract_text(pdf)\n",
    "    \n",
    "    # Append text to list\n",
    "    texts.append(pdf_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_cleanned = []\n",
    "for text in texts:\n",
    "    \n",
    "    # Remove new lines\n",
    "    text_cleanned = re.sub(\"\\n\", \" \", text)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text_cleanned = re.sub(' +', ' ', text_cleanned)\n",
    "\n",
    "    # Replace tokens in uppercase including accented characters with title() method\n",
    "    text_cleanned = re.sub(r'\\b[A-ZÀ-ÿ]{2,}\\b', lambda x: x.group().title(), text_cleanned)\n",
    "\n",
    "    # Append 'text_cleanned' to list\n",
    "    texts_cleanned.append(text_cleanned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert2bert_shared-spanish-finetuned-summarization\")\n",
    "\n",
    "# Load model for Spanish summarization\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/bert2bert_shared-spanish-finetuned-summarization\")\n",
    "\n",
    "# Create instance for summarization task\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [07:53<00:00, 23.68s/it]\n"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "for text in tqdm(texts):\n",
    "\n",
    "    # Apply summarizer function to text\n",
    "    summary = summarizer(text, truncation=True, max_length=512)\n",
    "\n",
    "    # Append summary to list\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_cleanned = []\n",
    "for i in range(len(summaries)):\n",
    "    summaries_cleanned.append(list(summaries[i][0].values())[0])\n",
    "\n",
    "# Create dataframe from list\n",
    "df = pd.DataFrame(summaries_cleanned, columns=['resumen'])\n",
    "\n",
    "# Add new column\n",
    "df['texto'] = texts_cleanned\n",
    "\n",
    "df.to_csv('../data/processed/pdf_texto.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract information from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/spanish-t5-small-sqac-for-qa\")\n",
    "\n",
    "# Load model for Spanish Question-Answering\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/spanish-t5-small-sqac-for-qa\")\n",
    "\n",
    "# Create instance for text2text-generation task\n",
    "get_answer = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 20/20 [22:32<00:00, 67.63s/it] \n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for text in tqdm(texts_cleanned):\n",
    "\n",
    "    # Define question to answer\n",
    "    question = '¿Cuál es el nombre del expediente?'\n",
    "\n",
    "    # Apply question answering function to text\n",
    "    record = get_answer(f'question: {question}  context: {text}', truncation=True, max_length=512)\n",
    "   \n",
    "    # Append record to list\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}],\n",
       " [{'generated_text': 'eduardo rafael riggi'}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for text in tqdm(texts_cleanned):\n",
    "\n",
    "    # Define question to answer\n",
    "    question = '¿Cuál es la fecha de la firma?'\n",
    "\n",
    "    # Apply question answering function to text\n",
    "    date = get_answer(f'question: {question}  context: {text}', truncation=True, max_length=512)\n",
    "\n",
    "    # Append date to list\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract date from anwser\n",
    "def clean_date(data):\n",
    "    # Filter first value from dictionary\n",
    "    date_filtered = list(data[0].values())[0]\n",
    "    # Find all matching dates\n",
    "    date_cleanned = re.findall(r'(\\d+/\\d+/\\d+)', date_filtered)\n",
    "    date = date_cleanned[0]\n",
    "    return date\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_2_ner-Tur0vV_l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12716637d0a64ae0b1d58eac3001dfc572eb4f6cd32970f1e770e93b4b11e88a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
